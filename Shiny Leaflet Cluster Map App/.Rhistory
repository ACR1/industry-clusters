styler:::style_active_file()
Y
# This R script assembles prepared data files and variables for the
# "Build a Cluster" Shiny App.
# It was prepared for NoCO REDI's 2019 Cluster Exploration Workshop
# by A.C. Repella. Extensively commented to support novice R-shiny users.
# Code for the App (this file only) is released as CC-BY-SA 4.0.
# Data files are not included in this license and any content that
# crosswalks or otherwise aligns data with other sources (such as
# Emsi, U.S. Cluster Mapping, or the other cluster systems bundled here)
# can be considered the property of the organization that produced it.
# LOAD LIBRARIES
# if you don't have these installed, you'll need to do so:
# by typing: install.packages("library name") at the console
library(tidyverse) # overkill here, I think I'm just using dplyr and readr
library(readxl) # reads excel files
library(rlist)
## SET WORKING DIRECTORY TO THIS PATH
# if in rstudio doing an interactive run from the IDE
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# using R proper, running from command line or when sourcing this file from another file.
# setwd(getSrcDirectory()[1])
# This file expects all file paths below to be accurate. There are
# no quality checks in this script.
## CLEAR GLOBAL ENVIROMENT AND DEFINE OUTPUT FILE NAME
rm(list = ls())
# this is the name of the output file.
# this script saves the entire global environment to a .Rdata file
# or else you'll save whatever stuff is loaded in the environment already
output_file <- paste0("build_a_cluster_data_", Sys.Date(), ".Rdata")
# INPUT PATH FOR FILES THAT ARE USED BY MULTIPLE APPS
shared_input_path <- "../Shared_Files/"
## SET SOME APP VARIABLES
# this is the unlock code used in the app.
# set it to whatever string you want.
# you'll need to uncomment some code in the app to limit access
# to content
unlock_code <- "UNLOCK CODE"
# "Nice Names" for your regions. we use 2. you can modify code to use more
# these regions need to be identically named in 2 different scripts
# (see imported data secton below)
region1 <- "Small Region"
region2 <- "Medium Region"
regions <- c(region1, region2)
# LOAD DATA PREPPED IN ANOTHER SCRIPT
# subcluster files. they are prepped in a different script
#     (provided as "make_cluster_subcluster_tables_from_emsi_industry_table.R")
# our2 example files are 100% fake (real subclusters, synthetic numbers)
# we use two different subcluster geographies in this app:
subclusters1 <- read_csv(paste0(
shared_input_path,
"Small.Region-by-subcluster-final-2019.3-2019-11-27.csv"))
subclusters2 <- read_csv(paste0(
shared_input_path,
"Medium.Region-by-subcluster-final-2019.3-2019-11-27.csv"
))
# what's the current data year ?
# (max year to display -- needs to be in files above. no logic checks here.
the_year <- 2018
subclusters <- rbind(subclusters1, subclusters2)
# this CSV contains total jobs for any regions in the subcluster tables and the US
# its used to recalculate Location Quotient on the fly.
# prepped in the same script as subclusters
#     (provided as "make_cluster_subcluster_tables_from_emsi_industry_table.R")
totaljobs <- read_csv(paste0(shared_input_path, "total_jobs.csv"))
# these are the scale factors used in the bubble chart in the app
# if you don't like the chart scaling of bubbles --- change it by change these values
# see the app for the scaling function.
minjobs <- 1
maxjobs <- max(subclusters$jobs) * 2
# this is our short list of clusters our members initially were particularly interested in
# based upon output from Emsi's default "Cluster Identification' tool.
# you should replace it with the clusters you are particularly interested in
# see file for formatting requirements
# it can be copy and pasted from the appropriate columns in the crosswalk file.
shortlist <- read_csv(paste0(shared_input_path, "shortlist.csv"))
# a list of companies crosswalked to clusters.
# we assembled ours from a variety of sources, including our own BRE data.
# you can use library accessible databases (Reference USA? D&B?) or the Business Table in Emsi
# this example file is totally fake (you don't need to know our companies...)
# we've replaced company names with some famous artists and scientists
# (thanks Wikipedia lists).
# we've replaced the county where the company is based with a random letter
# on our list, we selected companies that represented larger orgs + niches
# for subclusters with more Naics or more diverse companies across the naics,
companies <- read_excel(paste0(
shared_input_path,
"representative-companies.xlsx"
))
# This is our crosswalk file for matching Emsi NAICS to U.S. Cluster Mapping NAICS.
# we renamed a couple of subclusters subtly because there are duplicate
# subcluster names across a few Clusters (see "metals"!)
xwalk <- read_xlsx(paste0(
shared_input_path,
"Emsi-NAICS-to-Porter-Cluster.xlsx"
))
# create vectors that are basically lists of the subclusters we want.
# this requires using a modified subcluster list (like we did above) so that
# each subcluster is a unique name and can be seperated from their Cluster
# without issue
priority.subclusters.list <- split(shortlist$Subcluster, shortlist$Cluster)
x <- subclusters2[which(subclusters2$year == 2018), ]
all.subclusters.list <- split(x$SubclusterName, x$Cluster)
x <- xwalk[which(xwalk$TradedLocal == "Traded"), ]
traded.subclusters.list <- split(x$SubclusterName, x$Cluster)
x <- xwalk[which(!(xwalk$TradedLocal == "Traded")), ]
local.subclusters.list <- split(x$SubclusterName, x$Cluster)
# this removes variables that are no longer needed.
rm(subclusters1, subclusters2, x, shortlist)
# this sets the initial choice list in the app.
# we set it to the priority subclusters, because that's
# the default selection in the app
choice_list <- priority.subclusters.list
# Data needs to be formatted as in the example excel file, but you can replace this with whatever systems you'd like to use for comparison
# FYI - R doesn't always like it when you try to open a file that is open in Excel,
# so close the XLSX file before attempting to run this script, or else you will get
# errors.
AL_clusters_df <- read_excel(paste0(
shared_input_path,"Other_Cluster_Definitions.xlsx"),
sheet = "AL_Clusters", col_types = c(
"text",
"text", "text", "text", "text",
"text", "text", "text"
)
)
MDEDC_clusters_df <- read_excel(paste0(
shared_input_path,"Other_Cluster_Definitions.xlsx"),
sheet = "MetroDenver", col_types = c(
"text",
"text", "text", "text", "text",
"text", "text", "text"
)
)
FC_clusters_df <- read_excel(paste0(
shared_input_path,"Other_Cluster_Definitions.xlsx"),
sheet = "FC_Clusters", col_types = c(
"text",
"text", "text", "text", "text",
"text", "text", "text"
)
)
OEDIT_clusters_df <- read_excel(paste0(
shared_input_path,"Other_Cluster_Definitions.xlsx"),
sheet = "OEDIT", col_types = c(
"text",
"text", "text", "text", "text",
"text", "text", "text"
)
)
# this is used in a chart. It's a medium gray. You can change the color with any HEX color
linecolor <- "#404040"
# this is used in the bubble chart. Bubble Colors for each region.
color_choices <- c('#E31737', '#787878')
# CHUNKS OF STATIC TEXT SHOWN IN THE APP --
## Any of this text can be styled with standard HTML.
# this is disclaimer text shown near the "Representative Companies" table in the app.
rep_cos_text <- c("These companies are representative of organizations with a presence in the region and an establishment that falls within this subcluster. This is not a comprehensive list. It is here to give concrete examples of the companies or types of companies that would appear in this particular cluster definition. Subclusters with very few establishments in the region are excluded, ")
# this is descriptive text below the bubble chart
# same deal, styles with HTML
bubble_chart_text <- c('This chart is a "Perdue Style" Bubble Chart that shows Location Quotient on the vertical axis and 5-year job growth on the horizontal axis. The size of the bubble represents total employment as of the data year. <br/><br/>The <b>top right</b> quadrant is typically viewed as a place of strength, a combination of job growth and regional specialization. <br />The <b>bottom right</b> indicates cluster that have strong job growth, but are not regional specializations (low LQ). <br />The <b>top left</b> indicates a decline in job growth, but a strong regional specialization.</br />The <b> bottom left </b> indicates a low specialization and job declines.<br/>                      The time series is presented because some clusters do show particular sensitivity to business cycles. <br /> ')
axis_font_style <- list(
family = "'Roboto Condensed', 'Arial Narrow', sans-serif",
size = 11,
color = "#404040"
)
## THIS SAVES ALL VARIABLES IN THE GLOBAL ENVIRONMENT TO A FILE
save.image(output_file)
runApp()
library("knitr")
rm(list=ls())
x = 1
rm(list=ls())
library(styler)
install.packages(styler)
install.packages("styler")
install.packages("styler")
styler:::style_active_file()
styler:::style_active_file()
# CONVERT TO LONG FORMAT
x <- emsi_table %>% gather(key = "Variable.Name", value = "value", -NAICS, -Description)
# LOAD LIBRARIES
# any libraries not on system will need to be added with
# command: 'install.packages("library name")'
library(tidyverse) # general data tidying summarizing
library(readxl) # reads XLSX files
library(stringr) # for formatting strings nicely
library(rlist) # for append
# if in rstudio doing an interactive run from the IDE
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# clear environment
rm(list = ls())
region1 <- "Small Region"
region2 <- "Medium Region"
region3 <- "Large Region"
# gather all your regions into a vector of region names
regions <- c(region1, region2, region3)
n_regions <- length(regions)
# These are Emsi Industry Tables. exported as CSV from Emsi.
# CSV as export is important for 2 reasons
#      1) all values that are <10 or insf. data are 0 in Csv
#      2) no total row is present
#              (this script assumes each row is unique NAICS, not total)
# Data is expected to be formatted in identically
# named and formatted columns as in example files
# ALL NUMERIC VALUES IN THESE EXAMPLE FILES ARE FAKE.
# 'emsi_table1' better be the same region as 'region1', and so on....
emsi_table1 <- read_csv("6d_NAICS_Industry_Table_export_for_Small_Region.csv")
emsi_table2 <- read_csv("6d_NAICS_Industry_Table_export_for_Medium_Region.csv")
emsi_table3 <- read_csv("6d_NAICS_Industry_Table_export_for_Large_Region.csv")
# drop them into a list for easy iteration.
# ORDER MUST match the regions vector defined above
emsi_tables <- list(emsi_table1, emsi_table2, emsi_table3)
n_tables <- length(emsi_tables)
# the regions and datatables need to match.
if (n_regions != n_tables) {
stop("number of regions and number of data tables don't match")
}
# THIS CROSSWALKS EMSI NAICS to U.S. Cluster Mapping Project Cluster/Subcluster defs
xwalk <- read_excel("Emsi-NAICS-to-Porter-Cluster.xlsx")
# currently writes up one higher in directory structure
output.path <- "../"
# puts the current date on file names
DATE <- Sys.Date()
# this is the number of years for multi-year averages. it's hardcoded into
# variable names so if you are using a different period, check/change the
# var names below where cluster and subcluster dataframes are created.
n_years_period <- 5
all_total_jobs <- list()
# LOOP through each table to summarize by cluster and subcluster, write to file.
for (i in (1:n_tables)) {
region_name <- regions[i]
emsi_table <- emsi_tables[[i]]
# FORCE NAICS TO CHAR
emsi_table$NAICS <- as.character(emsi_table$NAICS)
colnames(emsi_table) <- make.names(colnames(emsi_table))
# This defines the unique filenames for each regions summarized data
output_cluster_filename <- paste0(
make.names(regions[i]),
"-cluster-final-2019.3-", DATE, ".csv"
)
output_subcluster_filename <- paste0(
make.names(regions[i]),
"-by-subcluster-final-2019.3-", DATE, ".csv"
)
########################################################
## PROCESS THE DATA
# CONVERT TO LONG FORMAT
x <- emsi_table %>% gather(key = "Variable.Name", value = "value", -NAICS, -Description)
# EXTRACT VARIABLE YEAR from Variable.Name
x$year <- str_match(x$Variable.Name, "(\\d\\d\\d\\d)")
x$year <- x$year[, 1] # str_match returned 2 items per row. we want the first
# Extract actual Variable name (no year) from Variable.Name
x$Variable.Name2 <- sub("(\\d\\d\\d\\d)", "", x$Variable.Name, perl = TRUE)
# do some more substituting to get meaningful standard names
x$Variable.Name2 <- ifelse(grepl("Earnings", x$Variable.Name2), "Earnings", x$Variable.Name2)
x$Variable.Name2 <- ifelse(grepl("National", x$Variable.Name2), "National.Jobs", x$Variable.Name2)
x$Variable.Name2 <- ifelse(grepl("X.Jobs", x$Variable.Name2), "Jobs", x$Variable.Name2)
x$Variable.Name2 <- ifelse(grepl("Payrolled", x$Variable.Name2), "Establishments", x$Variable.Name2)
# grab only the columns  needed
x <- x[, c("NAICS", "Description", "year", "Variable.Name2", "value")]
# reformat from long to wide
emsi_table_tidy <- spread(x, Variable.Name2, value)
## Calculate aggregate variables
emsi_table_tidy <- group_by(emsi_table_tidy, NAICS) %>%
mutate(job_change_5yr = Jobs - lag(Jobs, n_years_period))
emsi_table_tidy <- group_by(emsi_table_tidy, NAICS) %>%
mutate(national_change_5yr = National.Jobs - lag(National.Jobs, n_years_period))
# MINIMUM YEAR For Data is really the minimum year for an n_years_period summary
min_year <- min(as.numeric(emsi_table_tidy$year)) + n_years_period
emsi_table_tidy <- subset(emsi_table_tidy, emsi_table_tidy$year >= min_year)
emsi_table_tidy$total_earnings <- emsi_table_tidy$Earnings * emsi_table_tidy$Jobs
# avoid doing math on suppressed values by zeroing out
# "earnings calc" jobs when earnings is NA
emsi_table_tidy$EarningsJobs <- ifelse(is.na(emsi_table_tidy$total_earnings),
0, emsi_table_tidy$Jobs
)
## calculate total jobs as sum of all industry jobs
## FYI: these totals may have small differences from the Emsi published totals
## that appear online or in the Excel file, this is due to values <10 being
## forced to 0 in CSV files, but those values are included in table totals.
## if this creates an unusual discrepancy in your results for LQ calculations..
## you might be using way too small of a region for cluster analysis.
## you can check to see if this is particularly different from your actual total
## estimates by checking values in this data frame (which is exported)
## vs. what you see in Emsi for your totals.
total_jobs <- emsi_table_tidy %>%
group_by(year) %>%
summarize(
region_jobs = sum(Jobs),
national_jobs = sum(National.Jobs)
)
## CREATE DFs  summarized by cluster or subcluster name.
cluster_df <- left_join(xwalk, emsi_table_tidy, by = "NAICS") %>%
group_by(Cluster, year) %>%
summarize(
jobs = sum(Jobs),
national.jobs = sum(National.Jobs),
jobs.change = sum(job_change_5yr),
national.jobs.change = sum(national_change_5yr),
jobs.pct.change = jobs.change / jobs,
Sum_Earnings = sum(total_earnings, na.rm = TRUE),
earnings.jobs = sum(EarningsJobs)
)
subcluster_df <- left_join(xwalk, emsi_table_tidy, by = "NAICS") %>%
group_by(Cluster, SubclusterName, year) %>%
summarize(
jobs = sum(Jobs),
national.jobs = sum(National.Jobs),
jobs.change = sum(job_change_5yr),
national.jobs.change = sum(national_change_5yr),
jobs.pct.change = jobs.change / jobs,
Sum_Earnings = sum(total_earnings, na.rm = TRUE),
earnings.jobs = sum(EarningsJobs)
)
# Recalculate average earnings
subcluster_df$average_earnings <- subcluster_df$Sum_Earnings / subcluster_df$earnings.jobs
cluster_df$average_earnings <- cluster_df$Sum_Earnings / cluster_df$earnings.jobs
# Recalculate Location Quotient
# first, initialize columns to 0.
cluster_df$LQ <- 0
subcluster_df$LQ <- 0
## USE TOTAL JOBS (calculated above) to calculate Location Quotient by Cluster/Sub
start_year <- min(cluster_df$year)
end_year <- max(cluster_df$year)
# subset total jobs to years in cluster/subcluster data frames
total_jobs <- total_jobs[which(total_jobs$year >= start_year & total_jobs$year <= end_year), ]
# Initialize a starting value for new columns before looping.
cluster_df$total.local.jobs <- 0
cluster_df$total.national.jobs <- 0
subcluster_df$total.local.jobs <- 0
subcluster_df$total.national.jobs <- 0
# iteratively calculating
for (i in 1:dim(total_jobs)[1]) {
t_emp_local <- as.numeric(total_jobs$region_jobs[i])
t_emp_national <- as.numeric(total_jobs$national_jobs[i])
n1 <- which(cluster_df$year == total_jobs$year[i])
n2 <- which(subcluster_df$year == total_jobs$year[i])
cluster_df$total.local.jobs[n1] <- t_emp_local
cluster_df$total.national.jobs[n1] <- t_emp_national
subcluster_df$total.local.jobs[n2] <- t_emp_local
subcluster_df$total.national.jobs[n2] <- t_emp_national
}
cluster_df$LQ <- (ifelse(cluster_df$jobs >= 1,
cluster_df$jobs, 1
) / cluster_df$total.local.jobs) /
(cluster_df$national.jobs / cluster_df$total.national.jobs)
subcluster_df$LQ <- (ifelse(subcluster_df$jobs >= 1,
subcluster_df$jobs, 1
) / subcluster_df$total.local.jobs) /
(subcluster_df$national.jobs / subcluster_df$total.national.jobs)
# TACK ON REGION NAME
cluster_df$region <- region_name
subcluster_df$region <- region_name
# FINAL CLEAN UP - this deletes unneeded columns
cluster_df$total.local.jobs <- NULL
cluster_df$total.national.jobs <- NULL
subcluster_df$total.local.jobs <- NULL
subcluster_df$total.national.jobs <- NULL
## COLLECT TOTAL JOBS FOR WRITING LATER
all_total_jobs %<>% list.append(data.frame(total_jobs))
## WRITE FILES
write_csv(cluster_df, paste0(output.path, output_cluster_filename))
write_csv(subcluster_df, paste0(output.path, output_subcluster_filename))
}
total_job_df <- all_total_jobs[[1]]
total_job_df <- total_job_df[, c(1, 3, 2)] # reorder the columns for general human reading
colnames(total_job_df) <- c("year", "total.us.jobs", regions[1])
for (i in (2:n_tables)) {
total_job_df[[regions[i]]] <- all_total_jobs[[i]]$region_jobs
}
write_csv(total_job_df, paste0(output.path, "total_jobs.csv"))
install.packages("sp")
# These are libraries that are needed
require(tidyverse) # for tidy cleaning/organizing/aggregating data
require(readxl) # importing an Excel file
require(magrittr) # included for the %<>% special pipe
library(sp) #
require(knitr) # for Kable tables
require(stats) # for weighted.mean()
require(scales) # for rescaling values
# this file is a crosswalk from Emsi NAICS definitions to the Porter Clusters.
# more details are in the file.
cluster_xwalk <- read_excel("../../Shared_Files/NAICS_crosswalks_to_Cluster_system.xlsx")
# if in rstudio doing an interactive run from the IDE...
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
## CLEAR GLOBAL ENVIROMENT ---------------------
rm(list = ls())
# LOAD libraries ---------------------
# if you don't have these installed, you'll need to do so:
# by typing: install.packages("library name") at the console
library(readxl) # reads excel files
library(tidyverse)
library(magrittr) # %<>%
# SET OUTPUT FILENAME ---------------------
# This will be sourced by the app.R file
out_file <- paste0("cluster_map_data_", Sys.Date(), ".Rdata")
## SET OPTIONAL UNLOCK CODE ---------------------
# if you want to publish this on Shinyapps.io,
# but won't be authenticating users, you
# may want to keep casual visitors from accessing your app by creating an
# "unlock code" that you can share with all of your users.
unlock_code <- "YOUR_OWN_PASSWORD"
# LIST U.S. CLUSTER MAPPING DEFINITIONS TO EXCLUDE FROM YOUR APP-------------
# This is a list of clusters that are too small in our region to map
# we exclude them from the map on purpose.
# each item needs to must match (case sensitive) the official definitions in the cluster lists.
cluster_exclusions <- c(
"Fishing and Fishing Products", "Footwear", "Forestry",
"Coal Mining", "Jewelry and Precious Metals",
"Metal Mining", "Textile Manufacturing",
"Paper and Packaging", "Music and Sound Recording",
"Tobacco", "Water Transportation"
)
# VARIOUS LISTS OF CLUSTERS -------------------------
# These form selection options in the app
# LIST any priority clusters
# our group defined clusters that were "priorities to learn about"
# see file for expected format
priority.clusters.list <- unname(unlist(
read_excel("../Shared_Files/lists_of_clusters.xlsx",
sheet = "priority")[, 1]))
# a list of traded (not local) clusters, check the file for format
traded.clusters.list <- unname(unlist(
read_excel("../Shared_Files/lists_of_clusters.xlsx",
sheet = "traded")[, 1]))
traded.clusters.list <- traded.clusters.list[which(!(traded.clusters.list %in%
cluster_exclusions))]
# a list of all clusters
all.clusters.list <- unname(unlist(
read_excel("../Shared_Files/lists_of_clusters.xlsx", sheet = "all")[, 1]))
all.clusters.list <- all.clusters.list[which(!(all.clusters.list %in% cluster_exclusions))]
# initial cluster choice in app
choice_list <- priority.clusters.list
# initialize a variable used in the app.
linked.clusters.list <- c(" ")
# LINKED CLUSTERS ---------------------
# this is an excel file with the cluster links defined on
# the 'related cluster' page at U.S. Cluster Mapping Project
# generated from "Full Portfolio View" at https://clustermapping.us/cluster
clusterLinks <- read_xlsx("../Shared_Files/ClusterLinkage.xlsx")
clusterLinks.list <- unique(clusterLinks$`Core Cluster`)
# CLUSTER POINTS TO MAP ---------------------
# this file represents point data of aggregated business establishments
# this is the output file from the "Create_Cluster_Map_Data.RMD file
# that steps through the process
cluster_points <- read_csv("cluster_gravity_points.csv")
# this is a message that appears below the map in the app.
# it describes how the map data was aggregated.
# it's formatted using HTML.
map_text <- paste0(
"<br /><br /><p>",
'Map shows "centers of gravity" for clusters in the region.',
"</p><p>",
"Click on any point to see details on employees + ",
"establishments, as well as radius included in each point.",
"</p><p>",
"Many small clusters indicate more small businesses ",
"within the cluster.",
"</p><p>",
"One or two single clusters means that large employers",
"dominate the total employment.",
"</p><p>",
"Clusters are calculated based upon the employment center by",
" Census tract.</p>",
'<p>Each cluster center of gravity "attracts" additional Census tracts until it meets publication criteria.</p>',
"<p>The map highlights geographic centers for multiple businesses, not individual worksites.</p>"
)
# this text explains what linked clusters are and shares a link
# to learn more. appears at the base of the left-side menu
# again, formatted using HTML
linked_cluster_text <- paste0(
"<small><i>linked, or related, clusters are",
"traded clusters that have close connections ",
"which may span co-location, shared workforce,",
"shared supply chain, or other interactions.</i>",
"</small><small><i>",
"A map showing these relationships can be viewed",
' here: <a href="https://clustermapping.us/',
'cluster#related-clusters" target="_blank"> U.S.',
" Cluster Mapping, Related Clusters </a>.",
"</i> </small>"
)
# this text describes the clusters that are excluded from the app
exclusion_text <- paste0(
"This map excludes these clusters due to their limited",
" importance in our region: ",
paste(cluster_exclusions, collapse = ", "), "."
)
disclaimer_text <- paste0(
"The code for this Shiny App has been released under",
" CC-BY-SA 4.0. Data, text, images and cluster",
" definitions displayed through implementation of",
" this app is not included under that agreement."
)
# this adds a field to the cluster points that contains descriptive
# text to the pop-up window when a point is clicked.
# it uses HTML to format display text in Leaflet map. <b> == bold, <br /> == line break
cluster_points$content <- paste0(
"<b>", cluster_points$Cluster,
"</b><br />Employed: ",
cluster_points$nice_emp_bin,
"<br />Establishments: ",
cluster_points$estabs
)
# WRITE ENVIROMENT TO FILE FOR APP -------------
save.image(file = out_file)
runApp()
install.packages("leaflet")
runApp()
library(styler)
require(styler)
library("styler")
